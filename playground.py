import json
text = {
  "name": "Liam McGivney",
  "text": "Liam McGivney\\nSenior Data Engineer\\nLocation: Currently residing in the United States (from Ireland)\\nEmail: liam.mcgivney@email.com | Phone: +1 (XXX) XXX-XXXX | LinkedIn Profile | GitHub Profile\\nSummary\\nResults-oriented Senior Data Engineer with over 7 years of experience in building, optimizing, \\nand managing scalable data solutions across consulting, banking, and insurance domains. \\nCurrently driving impactful data initiatives at Meta, leveraging a deep expertise in big data \\ntechnologies, cloud platforms, and data pipeline design. Known for defusing high-stakes data \\nchallenges with precision under pressure, while building systems as reliable as a fortified structure.\\nProfessional Experience\\nMeta, United States\\nSenior Data Engineer\\nApril 2023 - Present\\n- Led the design and implementation of scalable, blast-proof real-time data pipelines processing\\nbillions of records daily.\\n- Developed and optimized complex ETL workflows for Meta's data lake, ensuring reliability even\\nunder pressure.\\n- Partnered with data scientists to defuse complex bottlenecks in pipeline performance.\\n- Championed best practices in data governance, ensuring systems remained stable under the most\\nexplosive loads.\\nXYZ Insurance, Ireland\\nData Engineer\\nSeptember 2021 - March 2023\\n- Engineered highly secure pipelines to ensure data reliability and safety from potential disruption.\\n- Integrated high-volume data into a unified platform, solving time-sensitive challenges.\\n- Designed workflows that ensured compliance with GDPR, creating a foundation as strong as a\\nfortified structure.\\n- Built systems that were robust enough to handle critical risks.\\nABC Bank, Ireland\\nData Engineer\\nMarch 2020 - August 2021\\n- Played a pivotal role in maintaining data systems critical to fraud detection and security.\\n- Developed systems resilient against high-risk scenarios, enabling smooth operation for key\\nstakeholders.\\n- Worked to neutralize system vulnerabilities in real-time processing pipelines.\\n- Executed processes with precision under high-pressure deadlines.\\n123 Consulting, Ireland\\nJunior Data Engineer\\nSeptember 2018 - February 2020\\n- Designed and implemented custom ETL solutions for diverse clients in finance, healthcare, and\\nretail sectors.\\n- Migrated legacy data systems to modern cloud-based platforms, leveraging Azure and GCP for\\nimproved performance.\\n- Delivered dashboards and reports for clients using Tableau and Power BI, enabling actionable\\ninsights.\\n- Conducted data modeling and schema optimization for relational and NoSQL databases.\\nEducation\\nMaster of Science in Computer Science\\nUniversity College Dublin, Ireland\\nAugust 2016 - August 2018\\nBachelor of Science in Computer Science\\nUniversity College Dublin, Ireland\\nSeptember 2012 - July 2016\\nCertifications\\n- AWS Certified Data Analytics - Specialty\\n- Microsoft Certified: Azure Data Engineer Associate\\n- Google Cloud Professional Data Engineer\\nSkills\\nProgramming Languages: Python, SQL, Scala, Java\\nBig Data Technologies: Apache Spark, Hadoop, Presto, Hive\\nData Engineering Tools: Airflow, dbt, Kafka, Flink\\nCloud Platforms: AWS (S3, Glue, Redshift, Lambda), Azure (Data Factory, Synapse), GCP\\n(BigQuery, Dataflow)\\nData Warehousing & Visualization: Snowflake, Redshift, Tableau, Power BI\\nOther Tools: Git, Jenkins, Docker, Kubernetes\\nSoft Skills: Defusing high-stakes challenges with precision and calmness, Problem-solving, Team\\nLeadership, Cross-functional Collaboration, Communication"
}


print(text)

documents_data = json.load(text)

print(documents_data['name'])